{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3503,"status":"ok","timestamp":1714117444880,"user":{"displayName":"Kong Kong","userId":"12174995287770087580"},"user_tz":-720},"id":"6I5ok_ljDDxh","outputId":"25619d7b-c370-45c4-c8e5-4dbcc13b7fd7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["**Objective**\n","1. To modify an existing Skip-gram model and run it with your\n","own data.\n","\n","\n","**Task**\n","1. You will need the sample code on skip-gram from the lab.\n","2. Your task is to write your own method to replace\n","“remove_stop_words” to only consider all types of nouns and\n","verbs when computing the vector space model.\n","3. Test it with the existing data and then extend the data set by\n","adding other sentences and verify that the model gives the\n","”correct” output.\n","4. Write a method that outputs the nearest word for a given\n","word. Use this method to output the nearest word for all given\n","words in your dataset. (Hint: You can use Euclidean distance)\n"],"metadata":{"id":"g-3S654QcY8d"}},{"cell_type":"markdown","metadata":{"id":"a8jAps_wz5MT"},"source":["Convert words to vectors using Count Vectorizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1714117444881,"user":{"displayName":"Kong Kong","userId":"12174995287770087580"},"user_tz":-720},"id":"oIlR7TFJoktV","outputId":"1574fbdf-44e8-42ba-c48d-a8a0b7ae7aca"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]}],"source":["corpus = ['king is a strong man',\n","          'queen is a wise woman',\n","          'boy is a young man',\n","          'girl is a young woman',\n","          'prince is a young king',\n","          'princess is a young queen',\n","          'man is strong',\n","          'woman is pretty',\n","          'prince is a boy will be king',\n","          'princess is a girl will be queen']\n","\n","\n","import os\n","# Initialize an empty list to store the contents of the articles\n","articles = []\n","# Directory containing NBA articles\n","directory = \"/content/drive/MyDrive/Colab Notebooks/TextMining/lab04-res\"\n","\n","# Iterate through each file in the directory\n","for filename in os.listdir(directory):\n","    filepath = os.path.join(directory, filename)\n","    if os.path.isfile(filepath):\n","        # Read the content of the file and append it to the list\n","        with open(filepath, 'r') as file:\n","            articles.append(file.read())\n","\n","# 先不启用\n","#corpus = articles\n","\n","\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.tag import pos_tag\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","\n","def remove_stop_words(corpus):\n","    stop_words = set(stopwords.words('english'))\n","    results = []\n","\n","    for text in corpus :\n","      print(text);\n","      tokens = word_tokenize(text)\n","      tagged_words = pos_tag(tokens)\n","      print(\"tagged_words:\",tagged_words)\n","      # only consider all types of nouns and verbs\n","      filtered_words = [word for word, pos in tagged_words if (pos.startswith('N') or pos.startswith('V')) and word.lower() not in stop_words]\n","      results.append(' '.join(filtered_words))\n","\n","    return results\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2rRmbN4Az76a"},"source":["TFIDF Example"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1714117444881,"user":{"displayName":"Kong Kong","userId":"12174995287770087580"},"user_tz":-720},"id":"2vuoregIyemU","outputId":"3d033f15-6145-4fef-ee55-54485e5fbd3f"},"outputs":[{"output_type":"stream","name":"stdout","text":["king is a strong man\n","tagged_words: [('king', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('strong', 'JJ'), ('man', 'NN')]\n","queen is a wise woman\n","tagged_words: [('queen', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('wise', 'NN'), ('woman', 'NN')]\n","boy is a young man\n","tagged_words: [('boy', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('young', 'JJ'), ('man', 'NN')]\n","girl is a young woman\n","tagged_words: [('girl', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('young', 'JJ'), ('woman', 'NN')]\n","prince is a young king\n","tagged_words: [('prince', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('young', 'JJ'), ('king', 'NN')]\n","princess is a young queen\n","tagged_words: [('princess', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('young', 'JJ'), ('queen', 'NN')]\n","man is strong\n","tagged_words: [('man', 'NN'), ('is', 'VBZ'), ('strong', 'JJ')]\n","woman is pretty\n","tagged_words: [('woman', 'NN'), ('is', 'VBZ'), ('pretty', 'JJ')]\n","prince is a boy will be king\n","tagged_words: [('prince', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('boy', 'NN'), ('will', 'MD'), ('be', 'VB'), ('king', 'VBG')]\n","princess is a girl will be queen\n","tagged_words: [('princess', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('girl', 'NN'), ('will', 'MD'), ('be', 'VB'), ('queen', 'JJ')]\n","=====================================\n","words: {'woman', 'boy', 'princess', 'man', 'girl', 'queen', 'king', 'wise', 'prince'}\n"]}],"source":["corpus = remove_stop_words(corpus)\n","#print(corpus)\n","print(\"=====================================\")\n","words = []\n","\n","for text in corpus :\n","    for word in text.split(' ') :\n","        words.append(word)\n","\n","words = set(words)\n","print(\"words:\",words)"]},{"cell_type":"markdown","source":["**Extract the words - skipgrams**"],"metadata":{"id":"pjEeBsKpibuI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jTM8Y6qqwAZC"},"outputs":[],"source":["word2int = {}\n","\n","for i,word in enumerate(words) :\n","    word2int[word] = i\n","\n","sentences = []\n","for sentence in corpus :\n","    sentences.append(sentence.split())\n","    #print(sentences)\n","\n","WINDOW_SIZE = 2\n","\n","data = []\n","for sentence in sentences :\n","    for idx,word in enumerate(sentence) :\n","        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] :\n","            if neighbor != word :\n","                data.append([word, neighbor])"]},{"cell_type":"code","source":["import pandas as pd\n","\n","for text in corpus :\n","    print(text)\n","\n","df = pd.DataFrame(data, columns = ['input', 'label'])\n","print(df.head(10))\n","df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mkua2F-4l2PF","executionInfo":{"status":"ok","timestamp":1714117444881,"user_tz":-720,"elapsed":7,"user":{"displayName":"Kong Kong","userId":"12174995287770087580"}},"outputId":"e54c8116-e170-4939-f0c7-3e341515d74b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["king man\n","queen wise woman\n","boy man\n","girl woman\n","prince king\n","princess queen\n","man\n","woman\n","prince boy king\n","princess girl\n","   input  label\n","0   king    man\n","1    man   king\n","2  queen   wise\n","3  queen  woman\n","4   wise  queen\n","5   wise  woman\n","6  woman  queen\n","7  woman   wise\n","8    boy    man\n","9    man    boy\n"]},{"output_type":"execute_result","data":{"text/plain":["(24, 2)"]},"metadata":{},"execution_count":16}]},{"metadata":{"id":"5Ihk-sCh0HU6"},"cell_type":"markdown","source":["# **Define a Tensor flow model**"]},{"cell_type":"code","source":["# importing Tensorflow\n","import tensorflow.compat.v1 as tf # use legacly tensor flow\n","\n","# disabling eager mode\n","tf.compat.v1.disable_eager_execution()\n","import numpy as np\n","\n","ONE_HOT_DIM = len(words)\n","\n","# one-hot-encoding\n","def to_one_hot_encoding(data_point_index) :\n","    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n","    one_hot_encoding[data_point_index] = 1\n","\n","    return one_hot_encoding\n","\n","X = [] # input word\n","Y = [] # target word\n","\n","for x, y in zip(df['input'], df['label']) :\n","    X.append(to_one_hot_encoding(word2int[ x ]))\n","    Y.append(to_one_hot_encoding(word2int[ y ]))\n","\n","# numpy array\n","X_train = np.asarray(X)\n","Y_train = np.asarray(Y)\n","\n","# X_train Y_train placeholder\n","x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n","#在这段代码中，x 是一个输入占位符，用于接收输入数据，它的形状是 (None, ONE_HOT_DIM)，\n","# 其中 None 表示可以接收任意数量的输入样本，\n","# ONE_HOT_DIM 表示每个样本的维度为 ONE_HOT_DIM。\n","# 这样设计的目的是为了能够处理不同大小的输入数据集。\n","\n","y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n","\n","# word embedding\n","EMBEDDING_DIM = 2\n","\n","# hidden layer\n","W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n","#创建了一个形状为 [ONE_HOT_DIM, EMBEDDING_DIM] 的 TensorFlow 变量（Variable），\n","#  其中 ONE_HOT_DIM 表示输入特征的维度（即输入的 one-hot 编码向量的维度），\n","#  EMBEDDING_DIM 表示隐藏层的维度（即隐藏单元的数量）。\n","\n","# 这个变量 W1 包含了输入层到隐藏层的权重参数，初始值为从正态分布中随机采样的值。\n","b1 = tf.Variable(tf.random_normal([1])) # bias\n","#创建了一个形状为 [1] 的 TensorFlow 变量，表示隐藏层的偏置（bias）。\n","#这个偏置向量 b1 用于在权重矩阵和输入数据相乘后的结果上加上一个常数偏置项。\n","hidden_layer = tf.add(tf.matmul(x,W1), b1)\n","#计算了隐藏层的输出。首先，使用 tf.matmul 函数对输入数据 x 和权重矩阵 W1 进行矩阵相乘，得到输入数据在隐藏层的投影。\n","#然后，使用 tf.add 函数将投影结果和偏置向量 b1 相加，得到隐藏层的未激活输出\n","\n","# output layer\n","W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n","b2 = tf.Variable(tf.random_normal([1]))\n","prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n","\n","#W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))：创建了一个形状为 [EMBEDDING_DIM, ONE_HOT_DIM] 的 TensorFlow 变量（Variable），表示隐藏层到输出层的权重矩阵。\n","#   其中 EMBEDDING_DIM 是隐藏层的维度，ONE_HOT_DIM 是输出的维度（即标签的数量）。这个权重矩阵 W2 包含了隐藏层到输出层的连接权重，初始值为从正态分布中随机采样的值。\n","\n","#b2 = tf.Variable(tf.random_normal([1]))：创建了一个形状为 [1] 的 TensorFlow 变量，表示输出层的偏置（bias）。这个偏置向量 b2 用于在隐藏层的输出结果上加上一个常数偏置项。\n","\n","#tf.matmul(hidden_layer, W2)：使用 tf.matmul 函数对隐藏层的输出 hidden_layer 和权重矩阵 W2 进行矩阵相乘，得到隐藏层输出在输出层的投影。\n","\n","#tf.add(..., b2)：使用 tf.add 函数将投影结果和偏置向量 b2 相加，得到输出层的未激活输出。\n","\n","#tf.nn.softmax(...)：使用 softmax 函数对输出层的未激活输出进行激活，将其转换为表示类别概率的概率分布。softmax 函数会对向量中的每个元素进行指数运算，然后将结果归一化为一个概率分布，使得所有元素的和为 1。\n","\n","#最终，prediction 变量包含了神经网络的输出，它表示输入数据在各个类别上的概率分布。在训练过程中，通过不断调整权重矩阵和偏置向量的值，以最小化损失函数来优化神经网络的性能。\n","\n","\n","# loss function : cross entropy\n","loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n","#定义了损失函数，使用的是交叉熵（cross entropy）损失函数。交叉熵是用于度量两个概率分布之间差异性的一种方法，在分类问题中常用于衡量预测值与真实标签之间的差异。\n","#具体地，这段代码中使用了 TensorFlow 的函数来计算交叉熵损失，其中 y_label 是真实的标签数据，prediction 是神经网络的输出。\n","#这个损失函数计算了每个样本的交叉熵，并通过 tf.reduce_mean 函数计算了所有样本的平均交叉熵。\n","\n","#在 TensorFlow 中，axis=[1] 的作用是指定在哪个轴上进行求和操作。具体来说，对于 tf.reduce_sum 函数，axis=[1] 表示沿着第二个维度（索引从 0 开始）对张量进行求和。\n","\n","#在这段代码中，y_label * tf.log(prediction) 计算了每个样本的交叉熵，其中 y_label 是真实的标签数据，prediction 是神经网络的输出。然后，tf.reduce_sum 函数将这些交叉熵沿着第二个维度进行求和，即对每个样本的交叉熵进行求和，得到一个包含每个样本损失的一维张量。最后，tf.reduce_mean 函数计算了这个一维张量的平均值，得到整个批次样本的平均交叉熵，作为损失函数的值。\n","\n","#在 TensorFlow 中，张量的维度从 0 开始索引。对于二维张量（矩阵），第一个维度通常表示行数，第二个维度表示列数。因此，沿着第二个维度进行操作意味着沿着列的方向进行操作。\n","\n","#在一些文档中，特别是在深度学习的上下文中，第一个维度通常是批次大小（batch size），而第二个维度是特征或神经元的数量。在这种情况下，沿着第二个维度进行操作意味着在每个样本中进行操作，而不是在整个批次中进行操作。\n","\n","#在上述代码中，axis=[1] 表示对每个样本的损失进行求和，而不是对整个批次的损失进行求和。这样可以得到每个样本的损失，然后再通过 tf.reduce_mean 函数计算这些损失的平均值，得到整个批次的平均损失。\n","\n","# training operation\n","train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n","#定义了训练操作，使用的是梯度下降优化器。梯度下降是一种常用的优化算法，用于调整神经网络中的参数（权重和偏置），使得损失函数最小化。\n","#在这段代码中，使用了 TensorFlow 的 GradientDescentOptimizer 类创建了一个梯度下降优化器，学习率为 0.05，然后调用 minimize 方法来最小化损失函数 loss，\n","#这样 TensorFlow 就会自动计算损失函数对所有可训练参数的梯度，并更新参数以降低损失。"],"metadata":{"id":"T3iQ9I2rmLyU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Input\")\n","print(X_train.shape)\n","print(X_train)\n","print(\"Output\")\n","print(X_train.shape)\n","print(Y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XqywbJRYnEdE","executionInfo":{"status":"ok","timestamp":1714117444882,"user_tz":-720,"elapsed":6,"user":{"displayName":"Kong Kong","userId":"12174995287770087580"}},"outputId":"5ab53498-0350-4a7f-e2c5-8f40f67cdfff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input\n","(24, 9)\n","[[0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n","Output\n","(24, 9)\n","[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"]}]},{"metadata":{"id":"eCAYr3P76fN-"},"cell_type":"markdown","source":["# **Train the model**"]},{"cell_type":"code","source":["sess = tf.Session()\n","#通过执行会话中的初始化操作，初始化了所有的全局变量，包括权重矩阵和偏置向量。\n","init = tf.global_variables_initializer()\n","sess.run(init)\n","\n","iteration = 20000\n","\n","for i in range(iteration) :\n","    # input : X_train(one-hot encoded word)\n","    # label : Y_train(one-hot encoded neighbor word)\n","    #在每次迭代中执行训练操作 train_op，其中使用了 feed_dict 参数来提供训练数据。x 表示输入数据（one-hot 编码的单词），y_label 表示标签数据（one-hot 编码的邻近单词）。\n","    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n","\n","    if i % 3000 == 0 :\n","        #打印当前迭代次数和对应的损失值\n","        print('iteration ' + str(i) + ' loss is : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50PuTDzonWa1","executionInfo":{"status":"ok","timestamp":1714117469322,"user_tz":-720,"elapsed":24445,"user":{"displayName":"Kong Kong","userId":"12174995287770087580"}},"outputId":"6652323c-7cec-4710-e453-8ae2cf67a6c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["iteration 0 loss is :  3.3058727\n","iteration 3000 loss is :  1.0441762\n","iteration 6000 loss is :  1.0217968\n","iteration 9000 loss is :  1.0115248\n","iteration 12000 loss is :  1.0048951\n","iteration 15000 loss is :  1.000134\n","iteration 18000 loss is :  0.9965022\n"]}]},{"cell_type":"markdown","source":["**2D coordinates for the words**"],"metadata":{"id":"j4cKlvHVneks"}},{"cell_type":"code","source":["vectors = sess.run(W1 + b1)\n","print(vectors)\n","\n","#这段代码用于获取输入层到隐藏层的权重矩阵和偏置项相加后的结果，并将其打印出来。\n","\n","#具体来说：\n","\n","#vectors = sess.run(W1 + b1)：这行代码通过 TensorFlow 的会话 sess 执行了一个操作，该操作将隐藏层的权重矩阵 W1 和偏置项 b1 相加，并将结果存储在 vectors 变量中。\n","#这里使用 sess.run 方法执行了 TensorFlow 图中的计算，因为在 TensorFlow 中，变量的值只能在会话中进行计算获取。\n","\n","#vectors 变量包含了输入层到隐藏层的权重矩阵和偏置项相加后的结果，这个结果可以被视为是隐藏层中每个单元的向量表示。"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YsRLimpengPr","executionInfo":{"status":"ok","timestamp":1714117469323,"user_tz":-720,"elapsed":13,"user":{"displayName":"Kong Kong","userId":"12174995287770087580"}},"outputId":"3683c54d-a7ce-4216-adc8-8a6d3c8e410f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.5099318   1.1165957 ]\n"," [ 0.08581504 -0.86526525]\n"," [ 2.328962    4.3622127 ]\n"," [ 2.5665584  -1.9151947 ]\n"," [-2.5408344   0.9325203 ]\n"," [-0.6125039   0.4679949 ]\n"," [ 0.8800154  -4.6206946 ]\n"," [-2.881882    4.7962494 ]\n"," [ 3.6587226  -1.5339397 ]]\n"]}]},{"metadata":{"id":"sUV4uMOG80T2"},"cell_type":"markdown","source":["# **Word Vector with the words**"]},{"cell_type":"code","source":["#vectors 转换为一个 DataFrame，其中包含两列，分别为 'x1' 和 'x2'，分别代表向量中的第一个和第二个元素。\n","w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n","print(words)\n","wordlist = list(words) #convert word set to list\n","print(w2v_df)\n","#行代码将单词列表 wordlist 添加到 DataFrame 中，作为一列名为 'word' 的新列，将词嵌入与相应的单词对应起来\n","w2v_df['word'] = wordlist\n","#这行代码重新排列 DataFrame 的列的顺序，将 'word' 列放在第一列，然后返回重新排列后的 DataFrame\n","w2v_df = w2v_df[['word', 'x1', 'x2']]\n","w2v_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":528},"id":"pLHrRcEOno6a","executionInfo":{"status":"ok","timestamp":1714117469324,"user_tz":-720,"elapsed":12,"user":{"displayName":"Kong Kong","userId":"12174995287770087580"}},"outputId":"03968d1d-c5a5-4051-9436-ee6a982a60dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'woman', 'boy', 'princess', 'man', 'girl', 'queen', 'king', 'wise', 'prince'}\n","         x1        x2\n","0  0.509932  1.116596\n","1  0.085815 -0.865265\n","2  2.328962  4.362213\n","3  2.566558 -1.915195\n","4 -2.540834  0.932520\n","5 -0.612504  0.467995\n","6  0.880015 -4.620695\n","7 -2.881882  4.796249\n","8  3.658723 -1.533940\n"]},{"output_type":"execute_result","data":{"text/plain":["       word        x1        x2\n","0     woman  0.509932  1.116596\n","1       boy  0.085815 -0.865265\n","2  princess  2.328962  4.362213\n","3       man  2.566558 -1.915195\n","4      girl -2.540834  0.932520\n","5     queen -0.612504  0.467995\n","6      king  0.880015 -4.620695\n","7      wise -2.881882  4.796249\n","8    prince  3.658723 -1.533940"],"text/html":["\n","  <div id=\"df-d2a24d5d-8b21-4e2d-a708-801fdbe59f14\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>x1</th>\n","      <th>x2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>woman</td>\n","      <td>0.509932</td>\n","      <td>1.116596</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>boy</td>\n","      <td>0.085815</td>\n","      <td>-0.865265</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>princess</td>\n","      <td>2.328962</td>\n","      <td>4.362213</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>man</td>\n","      <td>2.566558</td>\n","      <td>-1.915195</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>girl</td>\n","      <td>-2.540834</td>\n","      <td>0.932520</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>queen</td>\n","      <td>-0.612504</td>\n","      <td>0.467995</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>king</td>\n","      <td>0.880015</td>\n","      <td>-4.620695</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>wise</td>\n","      <td>-2.881882</td>\n","      <td>4.796249</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>prince</td>\n","      <td>3.658723</td>\n","      <td>-1.533940</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2a24d5d-8b21-4e2d-a708-801fdbe59f14')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d2a24d5d-8b21-4e2d-a708-801fdbe59f14 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d2a24d5d-8b21-4e2d-a708-801fdbe59f14');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d06cc382-2297-42eb-a354-9d7e19b9e46c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d06cc382-2297-42eb-a354-9d7e19b9e46c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d06cc382-2297-42eb-a354-9d7e19b9e46c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_f1cd7cd6-523d-4b86-8d99-d35bcdeea5e6\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('w2v_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_f1cd7cd6-523d-4b86-8d99-d35bcdeea5e6 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('w2v_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"w2v_df","summary":"{\n  \"name\": \"w2v_df\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"wise\",\n          \"boy\",\n          \"queen\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x1\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          -2.8818819522857666,\n          0.08581504225730896,\n          -0.6125038862228394\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x2\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          4.7962493896484375,\n          -0.8652652502059937,\n          0.46799489855766296\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":21}]},{"metadata":{"id":"sNv2F5WO8-KI"},"cell_type":"markdown","source":["**Plot the results**"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","fig, ax = plt.subplots()\n","\n","for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n","    ax.annotate(word, (x1,x2 ))\n","\n","PADDING = 1.0\n","x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n","y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n","x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n","y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n","\n","plt.xlim(x_axis_min,x_axis_max)\n","plt.ylim(y_axis_min,y_axis_max)\n","plt.rcParams[\"figure.figsize\"] = (10,10)\n","\n","\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"id":"bQiBDeZQnzSa","executionInfo":{"status":"ok","timestamp":1714117469324,"user_tz":-720,"elapsed":9,"user":{"displayName":"Kong Kong","userId":"12174995287770087580"}},"outputId":"ffbf5036-de5e-46cd-b620-44e432cbac9f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"El8hG90L1dxo"},"source":["Distance metrices"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1714117469324,"user":{"displayName":"Kong Kong","userId":"12174995287770087580"},"user_tz":-720},"id":"t4fEVIVlreYC","outputId":"9f6a31d0-a664-4a71-bde8-4eb3df69efd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["The nearest word to 'woman' is 'queen'.\n","The nearest word to 'boy' is 'queen'.\n","The nearest word to 'princess' is 'woman'.\n","The nearest word to 'man' is 'prince'.\n","The nearest word to 'girl' is 'queen'.\n","The nearest word to 'queen' is 'woman'.\n","The nearest word to 'king' is 'man'.\n","The nearest word to 'wise' is 'girl'.\n","The nearest word to 'prince' is 'man'.\n"]}],"source":["from nltk.metrics import *\n","from sklearn.metrics.pairwise import euclidean_distances\n","\n","#print(\"Euclidean Distnance: \",euclidean_distances(vector1.toarray()[0],vector1.toarray()[1]))\n","\n","\n","\n","def find_nearest_word(word, word_vectors):\n","    # Find the index of the given word in the word vectors dataframe\n","    index = word_vectors.index[word_vectors['word'] == word].tolist()[0]\n","\n","    # Get the vector representation of the given word\n","    target_vector = word_vectors.iloc[index, 1:].values.reshape(1, -1)\n","\n","    # Calculate Euclidean distances between the target word vector and all other word vectors\n","    distances = euclidean_distances(word_vectors.iloc[:, 1:], target_vector)\n","\n","    # Find the index of the word with the shortest distance (excluding the target word itself)\n","    nearest_index = distances.argpartition(1, axis=None)[1]\n","\n","    # Get the nearest word\n","    nearest_word = word_vectors.iloc[nearest_index]['word']\n","\n","    return nearest_word\n","\n","# Example usage:\n","# Assuming w2v_df is your word vectors dataframe\n","nearest_words = {}\n","for word in w2v_df['word']:\n","    nearest_words[word] = find_nearest_word(word, w2v_df)\n","\n","# Output the nearest word for all given words\n","for word, nearest_word in nearest_words.items():\n","    print(f\"The nearest word to '{word}' is '{nearest_word}'.\")\n","\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO0PwcvRz+UvDcKcWSg7n/f"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}