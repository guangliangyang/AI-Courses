{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e13fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.metrics import r2_score \n",
    "import math\n",
    "import seaborn as sb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c40911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that my data is cleaned\n",
    "Pak_data = pd.read_csv(\"Pakuranga.csv\")\n",
    "Pak_data[\"date\"] = pd.to_datetime(Pak_data[\"date\"]).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print('Number of rows and columns:', Pak_data.shape)\n",
    "print('\\n  \\n**** First 5 instances: \\n ')\n",
    "print(Pak_data.head(5))\n",
    "# Save it to CSV, the copy the tabular data to your report\n",
    "Pak_data.head(5).to_csv(\"Pakuranga5.csv\")\n",
    "\n",
    "print('\\n  \\n**** Summary statistics for the numerical features: \\n ')\n",
    "print(Pak_data.describe().T)\n",
    "# Save it to CSV, the copy the tabular data to your report\n",
    "Pak_data.describe().T.to_csv(\"Pakuranga_data_summary.csv\")\n",
    "\n",
    "# Visualising the results\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(Pak_data[\"date\"], Pak_data[\"Pak_PM10\"], color='blue', label='PM_10')\n",
    "\n",
    "ax.set_title('Pakuranga PM_10')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('PM10 (ug/m3)')\n",
    "ax.legend()\n",
    "\n",
    "# set up figure size\n",
    "fig.set_figheight(9)\n",
    "fig.set_figwidth(16)\n",
    "\n",
    "# format the date to YYYY-MM\n",
    "x_ticks_length = np.arange(len(Pak_data['date']))\n",
    "plt.xticks(x_ticks_length[::100],\n",
    "           pd.to_datetime(Pak_data['date'][::100]).dt.strftime('%Y-%m-%d'),\n",
    "           rotation=45)\n",
    "\n",
    "\"\"\"\n",
    "I am using 50 as NZ standard for 24 hour PM10 is 50 ug/m3.\n",
    "Research about NZ hourly pm10/pm2.5\n",
    "\"\"\"\n",
    "ax.axhline(y=50, xmin=0, xmax=1200, color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Just some inspiration.\n",
    "(Do a proper EDA (Exploratory data analysis )) !!\n",
    "\"\"\"\n",
    "\n",
    "Pak_data['year'] = pd.to_datetime(Pak_data['date']).dt.strftime('%y')\n",
    "Pak_data['month'] = pd.to_datetime(Pak_data['date']).dt.strftime('%b')\n",
    "Pak_data['DayofWeek'] = pd.to_datetime(Pak_data['date']).dt.strftime('%A')\n",
    "Pak_data['hour'] = pd.to_datetime(Pak_data['date']).dt.strftime('%H')\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1)\n",
    "fig.set_figheight(12)\n",
    "fig.set_figwidth(9)\n",
    "\n",
    "sns.boxplot(x='year', y='Pak_PM10', data=Pak_data, ax=ax1)\n",
    "sns.boxplot(x='month', y='Pak_PM10', data=Pak_data, ax=ax2)\n",
    "sns.boxplot(x='DayofWeek', y='Pak_PM10', data=Pak_data, ax=ax3)\n",
    "#sns.boxplot(x='hour', y='Pak_PM10', data=Pak_data, ax=ax4) I dont have hourly data but kept is as an example for your hourly data\n",
    "\n",
    "plt.show()\n",
    "Pak_data.to_csv(\"PakurangaWithTemporal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b93bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pak_data.hist(stacked=True, bins=10)\n",
    "#plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting correlation heatmap\n",
    "Pak_dataTemp = pd.read_csv(\"PakurangaWithTemporal.csv\")\n",
    "corrPak_dataTemp= Pak_dataTemp.corr()\n",
    "plt.figure(figsize = (12,11)) \n",
    "dataplot = sb.heatmap(Pak_dataTemp.corr(), cmap=\"YlGnBu\", annot=True)\n",
    "plt.title('Correlation Matrix Heatmap2') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3ca1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier Treatment -remove entries outside of 1st & 3rd quantiles. Apply it with care and justify it.\n",
    "Q1 = Pak_data.quantile(0.05) \n",
    "Q3 = Pak_data.quantile(0.95) \n",
    "IQR = Q3 - Q1 \n",
    "pm = Pak_data[~((Pak_data < (Q1 - 1.5 * IQR)) |(Pak_data > (Q3 + 1.5 * IQR))).any(axis=1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa42be92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "In Our example dataset I  made the lag 1 only.\n",
    "In Our example I am using ( training: 70%,  30% )\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "You may  want to use TimeSeriesSplit. It ensures  splitting  the data into windows of consecutive samples.\n",
    "                                      It ensures that the validation/test results are more realistic, \n",
    "                                      being evaluated on the data collected after the model was trained.\n",
    "\n",
    "\"\"\"\n",
    "df=Pak_data.iloc[:, 1:9]\n",
    "column_indices = {name: i for i, name in enumerate(df.columns)}\n",
    "\n",
    "n = len(df)\n",
    "train_df = df[0:int(n * 0.7)]  # 0 ~~ 70%\n",
    "test_df = df[int(n * 0.7):]  # 70% ~~ end\n",
    "\n",
    "#num_features = df.shape[1]\n",
    "\n",
    "#Perfrom data prepration if required. Here I did not scale my data. \n",
    "#Also You might want to include hour, day, day of week or month too.\n",
    "\n",
    "feature_cols = ['Temp',\n",
    "                'Rain', 'RH',\n",
    "                'WD','WS',\n",
    "                'Solar',\n",
    "                'Lag1']\n",
    "\n",
    "value_col = ['Pak_PM10']\n",
    "\n",
    "train_features = train_df[feature_cols].values\n",
    "train_y = train_df[value_col].values\n",
    "\n",
    "test_features = test_df[feature_cols].values\n",
    "test_y = test_df[value_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's say : first layer : 100 neron, second layer : 50 neron, third layer : 25 neron\n",
    "model = MLPRegressor(hidden_layer_sizes=(100,50,25), max_iter=200,random_state=42)\n",
    "model.fit(train_features, train_y)\n",
    "\n",
    "# make predictions \n",
    "preds = model.predict(test_features)\n",
    "\n",
    "#Compute evaluation scores \n",
    "mse = mean_squared_error(test_y,preds) \n",
    "rmse = math.sqrt(mse) \n",
    "mae = mean_absolute_error(test_y,preds) \n",
    "r2= r2_score(test_y,preds) \n",
    "n_iter=model.n_iter_\n",
    "print(\"Root Mean Squared Error: \", rmse) \n",
    "print(\"Mean Absoloute Error: \", mae) \n",
    "print(\"R squared: \", r2)\n",
    "print(\"Number of iterations: \", n_iter)\n",
    "\n",
    "\"\"\"\n",
    "This is a very simple model\n",
    "refer to this tutorial\n",
    " \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html?highlight=mlpregressor\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b15e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
