{"cells":[{"cell_type":"markdown","id":"9515776d","metadata":{"id":"9515776d"},"source":["# COMP809 - Lab 4"]},{"cell_type":"code","execution_count":null,"id":"00322c6c","metadata":{"id":"00322c6c"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.utils import resample\n","import statsmodels.api as sm;\n","import scipy;\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA"]},{"cell_type":"code","execution_count":null,"id":"2a46bdf4","metadata":{"id":"2a46bdf4"},"outputs":[],"source":["df = pd.read_csv(\"framingham.csv\");\n","df = df.dropna(); # eliminate NAs"]},{"cell_type":"markdown","id":"8958d6c3","metadata":{"id":"8958d6c3"},"source":["## Question 1"]},{"cell_type":"code","execution_count":null,"id":"e10004f3","metadata":{"id":"e10004f3","outputId":"e0f18a12-d96a-44d3-8b8e-031550365167"},"outputs":[{"name":"stdout","output_type":"stream","text":["TenYearCHD\n","0    3099\n","1     557\n","Name: TenYearCHD, dtype: int64\n","Percentage of 0s: 84.76477024070022\n","Percentage of 1s: 15.23522975929978\n"]}],"source":["# Yes, the data is unbalanced.  We have 85% of 0s and 15% of 1s.\n","\n","response_count = df.groupby(\"TenYearCHD\")[\"TenYearCHD\"].count();\n","print(response_count);\n","print(\"Percentage of 0s:\", 100*response_count[0]/np.sum(response_count));\n","print(\"Percentage of 1s:\", 100*response_count[1]/np.sum(response_count));\n","\n","df.describe();"]},{"cell_type":"markdown","id":"e60c226e","metadata":{"id":"e60c226e"},"source":["### Question 1 (a)"]},{"cell_type":"code","execution_count":null,"id":"0a1c82df","metadata":{"id":"0a1c82df"},"outputs":[],"source":["# Note that if we train the model with this data set, the model could just predict any response\n","# as a 0, for any predictor values, having an approximated accuracy 0.85."]},{"cell_type":"markdown","id":"141f693b","metadata":{"id":"141f693b"},"source":["### Question 1 (b)"]},{"cell_type":"code","execution_count":null,"id":"29220bb2","metadata":{"id":"29220bb2"},"outputs":[],"source":["# One of the techniques to deal with unbalanced data is oversampling.\n","# This method works as follows: those observations with a response value that is minority are\n","# sampled with replacement M times, where M is the number of observations with a response value\n","# that is majority.\n","\n","# Thus, failures and successes are equated\n","\n","# We could also apply downsampling, in which case observations from the majority group are\n","# randomly removed to equate this category to the minority group."]},{"cell_type":"markdown","id":"012e6cf8","metadata":{"id":"012e6cf8"},"source":["## Question 1 (c)"]},{"cell_type":"code","execution_count":null,"id":"158a5c4c","metadata":{"id":"158a5c4c","outputId":"810bf6b0-e321-416d-d5fb-6e54ce3d2249"},"outputs":[{"name":"stdout","output_type":"stream","text":["TenYearCHD\n","0    3099\n","1    3099\n","Name: TenYearCHD, dtype: int64\n","                 Generalized Linear Model Regression Results                  \n","==============================================================================\n","Dep. Variable:             TenYearCHD   No. Observations:                 6198\n","Model:                            GLM   Df Residuals:                     6182\n","Model Family:                Binomial   Df Model:                           15\n","Link Function:                  Logit   Scale:                          1.0000\n","Method:                          IRLS   Log-Likelihood:                -3722.0\n","Date:                Fri, 22 Mar 2024   Deviance:                       7444.1\n","Time:                        11:09:51   Pearson chi2:                 6.17e+03\n","No. Iterations:                     5   Pseudo R-squ. (CS):             0.1691\n","Covariance Type:            nonrobust                                         \n","===========================================================================================\n","                              coef    std err          z      P>|z|      [0.025      0.975]\n","-------------------------------------------------------------------------------------------\n","Intercept                  -6.5345      0.405    -16.119      0.000      -7.329      -5.740\n","C(male)[T.1]                0.5247      0.062      8.524      0.000       0.404       0.645\n","C(currentSmoker)[T.1]       0.0564      0.093      0.605      0.545      -0.126       0.239\n","C(BPMeds)[T.1.0]           -0.0061      0.159     -0.039      0.969      -0.318       0.306\n","C(prevalentStroke)[T.1]     0.6933      0.341      2.036      0.042       0.026       1.361\n","C(prevalentHyp)[T.1]        0.3200      0.081      3.954      0.000       0.161       0.479\n","C(diabetes)[T.1]            0.1975      0.207      0.953      0.341      -0.209       0.604\n","age                         0.0644      0.004     16.707      0.000       0.057       0.072\n","education                  -0.0605      0.028     -2.193      0.028      -0.114      -0.006\n","cigsPerDay                  0.0203      0.004      5.281      0.000       0.013       0.028\n","totChol                     0.0018      0.001      2.877      0.004       0.001       0.003\n","sysBP                       0.0147      0.002      6.445      0.000       0.010       0.019\n","diaBP                      -0.0086      0.004     -2.298      0.022      -0.016      -0.001\n","BMI                         0.0192      0.007      2.639      0.008       0.005       0.033\n","heartRate                   0.0006      0.002      0.268      0.788      -0.004       0.005\n","glucose                     0.0051      0.001      3.615      0.000       0.002       0.008\n","===========================================================================================\n","8592.252450221082\n","7444.072190827779\n","Saturated model -- p-value:  0.0\n","Pearson2 / Df 0.9983049087888635\n","                 Generalized Linear Model Regression Results                  \n","==============================================================================\n","Dep. Variable:             TenYearCHD   No. Observations:                 6198\n","Model:                            GLM   Df Residuals:                     6182\n","Model Family:                Binomial   Df Model:                           15\n","Link Function:                  Logit   Scale:                         0.99830\n","Method:                          IRLS   Log-Likelihood:                -3722.0\n","Date:                Fri, 22 Mar 2024   Deviance:                       7444.1\n","Time:                        11:09:51   Pearson chi2:                 6.17e+03\n","No. Iterations:                     7   Pseudo R-squ. (CS):             0.1691\n","Covariance Type:            nonrobust                                         \n","===========================================================================================\n","                              coef    std err          z      P>|z|      [0.025      0.975]\n","-------------------------------------------------------------------------------------------\n","Intercept                  -6.5345      0.405    -16.133      0.000      -7.328      -5.741\n","C(male)[T.1]                0.5247      0.062      8.531      0.000       0.404       0.645\n","C(currentSmoker)[T.1]       0.0564      0.093      0.606      0.545      -0.126       0.239\n","C(BPMeds)[T.1.0]           -0.0061      0.159     -0.039      0.969      -0.318       0.306\n","C(prevalentStroke)[T.1]     0.6933      0.340      2.038      0.042       0.026       1.360\n","C(prevalentHyp)[T.1]        0.3200      0.081      3.957      0.000       0.162       0.478\n","C(diabetes)[T.1]            0.1975      0.207      0.954      0.340      -0.208       0.603\n","age                         0.0644      0.004     16.721      0.000       0.057       0.072\n","education                  -0.0605      0.028     -2.195      0.028      -0.114      -0.006\n","cigsPerDay                  0.0203      0.004      5.285      0.000       0.013       0.028\n","totChol                     0.0018      0.001      2.879      0.004       0.001       0.003\n","sysBP                       0.0147      0.002      6.450      0.000       0.010       0.019\n","diaBP                      -0.0086      0.004     -2.300      0.021      -0.016      -0.001\n","BMI                         0.0192      0.007      2.641      0.008       0.005       0.033\n","heartRate                   0.0006      0.002      0.269      0.788      -0.004       0.005\n","glucose                     0.0051      0.001      3.618      0.000       0.002       0.008\n","===========================================================================================\n"]}],"source":["# Oversampling\n","df_minority = df[(df['TenYearCHD']==1)];\n","df_majority = df[(df['TenYearCHD']==0)];\n","df_minority_upsampled = resample(df_minority,\n","                                 replace=True,     # sample with replacement\n","                                 n_samples= response_count[0], # to match majority class\n","                                 random_state=123);  # reproducible results\n","df_minority_upsampled.reset_index(drop=True, inplace=True); # reseting row numbers\n","\n","# Combine majority class with upsampled minority class\n","df_upsampled = pd.concat([df_minority_upsampled, df_majority]);\n","response_count = df_upsampled.groupby(\"TenYearCHD\")[\"TenYearCHD\"].count();\n","print(response_count);\n","\n","# Undersampling -- in case you want to use this option\n","# downsample majority class\n","#df_majority_downsampled = resample(df_majority,\n","#                                 replace=False,    # sample with replacement\n","#                                 n_samples= response_count[1], # to match minority class\n","#                                 random_state=123);  # reproducible results\n","\n","#print(df_minority_upsampled)\n","#list(df_minority_upsampled.columns)\n","\n","model  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + age + education + C(currentSmoker) + \\\n","                             cigsPerDay + C(BPMeds) + C(prevalentStroke) + C(prevalentHyp) + C(diabetes) + \\\n","                             totChol + sysBP + diaBP + BMI + heartRate+ glucose\", family = sm.families.Binomial(),\n","                             data=df_upsampled);\n","result = model.fit();\n","print(result.summary());\n","\n","# The null deviance shows how well the response is predicted by the model with nothing but an intercept\n","print(result.null_deviance);\n","# The residual deviance shows how well the response is predicted by the model when the predictors are included.\n","print(result.deviance);\n","\n","# Since there are many continuous predictors, it is highly likely that the responses are ungrouped,\n","# in which case the overdispersion cannot occur.\n","# But we will check it anyway.\n","\n","dev = result.deviance; # Residual Deviance\n","dof = result.df_resid; # Degree of freedoms of Residuals\n","pvalue = 1 - scipy.stats.chi2.cdf(dev, dof); # p-value\n","# H0: Logistic regression model provides an adequate fit for the data\n","# H1: Logistic regression model does not provide an adequate fit for the data\n","if pvalue < 0.05:\n","    print(\"Saturated model -- p-value: \", pvalue);\n","else :\n","    print(\"Logistic model is ok -- p-value=\", pvalue); #\n","\n","# Rules of thumb\n","\n","# Calculation of Pearson chi2 / n - (p+1)\n","print(\"Pearson2 / Df\",result.pearson_chi2 / result.df_resid);\n","# This value is close to 1\n","\n","# We also fit a quasi-binomial model\n","result2 = model.fit(scale=\"X2\");\n","print(result2.summary());\n","\n","# The scale parameter is close to 1 in this model\n","\n","# Conclusion: the logistic regression model provides an adequate fit for the data,\n","# even though this hypothesis was rejected according to the chi-square test.\n","\n","# See chaper 13 of Introduction to linear regression analysis\n","# by Montgomery, Douglas C., author.; Peck, Elizabeth A., author.; Vining, G. Geoffrey, author.\n","# to know about model selection criteria.\n"]},{"cell_type":"code","execution_count":null,"id":"33f24610","metadata":{"id":"33f24610","outputId":"831aa478-de1c-4a72-de46-5d4fde912233"},"outputs":[{"name":"stdout","output_type":"stream","text":["                 Generalized Linear Model Regression Results                  \n","==============================================================================\n","Dep. Variable:             TenYearCHD   No. Observations:                 6198\n","Model:                            GLM   Df Residuals:                     6186\n","Model Family:                Binomial   Df Model:                           11\n","Link Function:                  Logit   Scale:                          1.0000\n","Method:                          IRLS   Log-Likelihood:                -3722.7\n","Date:                Fri, 22 Mar 2024   Deviance:                       7445.4\n","Time:                        11:09:55   Pearson chi2:                 6.17e+03\n","No. Iterations:                     5   Pseudo R-squ. (CS):             0.1689\n","Covariance Type:            nonrobust                                         \n","===========================================================================================\n","                              coef    std err          z      P>|z|      [0.025      0.975]\n","-------------------------------------------------------------------------------------------\n","Intercept                  -6.5088      0.361    -18.007      0.000      -7.217      -5.800\n","C(male)[T.1]                0.5239      0.061      8.616      0.000       0.405       0.643\n","C(prevalentStroke)[T.1]     0.6925      0.340      2.037      0.042       0.026       1.359\n","C(prevalentHyp)[T.1]        0.3231      0.080      4.031      0.000       0.166       0.480\n","age                         0.0642      0.004     16.787      0.000       0.057       0.072\n","education                  -0.0623      0.027     -2.266      0.023      -0.116      -0.008\n","cigsPerDay                  0.0221      0.003      8.797      0.000       0.017       0.027\n","totChol                     0.0019      0.001      2.924      0.003       0.001       0.003\n","sysBP                       0.0146      0.002      6.427      0.000       0.010       0.019\n","diaBP                      -0.0086      0.004     -2.305      0.021      -0.016      -0.001\n","BMI                         0.0189      0.007      2.615      0.009       0.005       0.033\n","glucose                     0.0060      0.001      5.486      0.000       0.004       0.008\n","===========================================================================================\n","                 Generalized Linear Model Regression Results                  \n","==============================================================================\n","Dep. Variable:             TenYearCHD   No. Observations:                 6198\n","Model:                            GLM   Df Residuals:                     6186\n","Model Family:                Binomial   Df Model:                           11\n","Link Function:                  Logit   Scale:                         0.99749\n","Method:                          IRLS   Log-Likelihood:                -3722.7\n","Date:                Fri, 22 Mar 2024   Deviance:                       7445.4\n","Time:                        11:09:55   Pearson chi2:                 6.17e+03\n","No. Iterations:                     7   Pseudo R-squ. (CS):             0.1689\n","Covariance Type:            nonrobust                                         \n","===========================================================================================\n","                              coef    std err          z      P>|z|      [0.025      0.975]\n","-------------------------------------------------------------------------------------------\n","Intercept                  -6.5088      0.361    -18.029      0.000      -7.216      -5.801\n","C(male)[T.1]                0.5239      0.061      8.627      0.000       0.405       0.643\n","C(prevalentStroke)[T.1]     0.6925      0.339      2.040      0.041       0.027       1.358\n","C(prevalentHyp)[T.1]        0.3231      0.080      4.036      0.000       0.166       0.480\n","age                         0.0642      0.004     16.808      0.000       0.057       0.072\n","education                  -0.0623      0.027     -2.269      0.023      -0.116      -0.008\n","cigsPerDay                  0.0221      0.003      8.808      0.000       0.017       0.027\n","totChol                     0.0019      0.001      2.928      0.003       0.001       0.003\n","sysBP                       0.0146      0.002      6.435      0.000       0.010       0.019\n","diaBP                      -0.0086      0.004     -2.308      0.021      -0.016      -0.001\n","BMI                         0.0189      0.007      2.618      0.009       0.005       0.033\n","glucose                     0.0060      0.001      5.493      0.000       0.004       0.008\n","===========================================================================================\n"]}],"source":["model  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + age + education + C(currentSmoker) + \\\n","                             cigsPerDay + C(BPMeds) + C(prevalentStroke) + C(prevalentHyp) + C(diabetes) + \\\n","                             totChol + sysBP + diaBP + BMI + heartRate+ glucose\", family = sm.families.Binomial(),\n","                             data=df_upsampled);\n","\n","# Deleting BPMeds since it has the highest p-value\n","model  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + age + education + C(currentSmoker) + \\\n","                             cigsPerDay + C(prevalentStroke) + C(prevalentHyp) + C(diabetes) + \\\n","                             totChol + sysBP + diaBP + BMI + heartRate+ glucose\", family = sm.families.Binomial(),\n","                             data=df_upsampled);\n","\n","# Deleting heartRate since it has the highest p-value\n","model  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + age + education + C(currentSmoker) + \\\n","                             cigsPerDay + C(prevalentStroke) + C(prevalentHyp) + C(diabetes) + \\\n","                             totChol + sysBP + diaBP + BMI + glucose\", family = sm.families.Binomial(),\n","                             data=df_upsampled);\n","\n","# Deleting C(currentSmoker) since it has the highest p-value\n","model  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + age + education + \\\n","                             cigsPerDay + C(prevalentStroke) + C(prevalentHyp) + C(diabetes) + \\\n","                             totChol + sysBP + diaBP + BMI + glucose\", family = sm.families.Binomial(),\n","                             data=df_upsampled);\n","\n","# Deleting diabetes since it has the highest p-value\n","model  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + age + education + \\\n","                             cigsPerDay + C(prevalentStroke) + C(prevalentHyp) +  \\\n","                             totChol + sysBP + diaBP + BMI + glucose\", family = sm.families.Binomial(),\n","                             data=df_upsampled);\n","\n","\n","result = model.fit();\n","print(result.summary());\n","\n","# Just to check the adequacy of the model\n","result2 = model.fit(scale=\"X2\");\n","print(result2.summary());\n","# Note that the scale parameter is close to 1, so the logistic regression model provides an adequate fit for the data"]},{"cell_type":"markdown","id":"66a385a4","metadata":{"id":"66a385a4"},"source":["## Question 1 (d)"]},{"cell_type":"code","execution_count":null,"id":"b8294dc2","metadata":{"id":"b8294dc2","outputId":"a63952d1-8b17-43e9-ab19-87f0c0dc606e"},"outputs":[{"name":"stdout","output_type":"stream","text":["If we increase in one unit the glucose level, the log odds of 10 year risk of coronary heart disease is expected to increase in 0.006 , holding the other predictors constant.\n","If we increase in one unit the glucose level, the odds of 10 year risk of coronary heart disease is expected to increase in  1.006 , holding the other predictors constant.\n"]}],"source":["print('If we increase in one unit the glucose level, the log odds of 10 year risk of coronary heart disease is expected to increase in',\\\n","      round(result.params[\"glucose\"],3), \", holding the other predictors constant.\")\n","\n","print('If we increase in one unit the glucose level, the odds of 10 year risk of coronary heart disease is expected to increase in ',\\\n","      round( np.exp(result.params[\"glucose\"]),3), \", holding the other predictors constant.\")"]},{"cell_type":"markdown","id":"b9e32822","metadata":{"id":"b9e32822"},"source":["## Question 2"]},{"cell_type":"code","execution_count":null,"id":"4e0f2fd4","metadata":{"id":"4e0f2fd4","outputId":"b72a8cce-e176-419e-e6fd-8c8912a7c501"},"outputs":[{"name":"stdout","output_type":"stream","text":["                 Generalized Linear Model Regression Results                  \n","==============================================================================\n","Dep. Variable:             TenYearCHD   No. Observations:                 4338\n","Model:                            GLM   Df Residuals:                     4322\n","Model Family:                Binomial   Df Model:                           15\n","Link Function:                  Logit   Scale:                          1.0000\n","Method:                          IRLS   Log-Likelihood:                -2624.8\n","Date:                Fri, 22 Mar 2024   Deviance:                       5249.6\n","Time:                        11:10:00   Pearson chi2:                 4.31e+03\n","No. Iterations:                     5   Pseudo R-squ. (CS):             0.1615\n","Covariance Type:            nonrobust                                         \n","===========================================================================================\n","                              coef    std err          z      P>|z|      [0.025      0.975]\n","-------------------------------------------------------------------------------------------\n","Intercept                  -6.2139      0.478    -13.002      0.000      -7.151      -5.277\n","C(male)[T.1]                0.4636      0.073      6.340      0.000       0.320       0.607\n","C(currentSmoker)[T.1]       0.0303      0.112      0.271      0.787      -0.189       0.249\n","C(BPMeds)[T.1.0]            0.1392      0.186      0.750      0.453      -0.225       0.503\n","C(prevalentStroke)[T.1]     0.5623      0.405      1.387      0.165      -0.232       1.357\n","C(prevalentHyp)[T.1]        0.3473      0.096      3.601      0.000       0.158       0.536\n","C(diabetes)[T.1]            0.0698      0.241      0.289      0.772      -0.403       0.542\n","age                         0.0642      0.005     14.007      0.000       0.055       0.073\n","education                  -0.0460      0.033     -1.404      0.160      -0.110       0.018\n","cigsPerDay                  0.0207      0.005      4.504      0.000       0.012       0.030\n","totChol                     0.0021      0.001      2.780      0.005       0.001       0.004\n","sysBP                       0.0129      0.003      4.804      0.000       0.008       0.018\n","diaBP                      -0.0104      0.004     -2.341      0.019      -0.019      -0.002\n","BMI                         0.0191      0.009      2.217      0.027       0.002       0.036\n","heartRate                   0.0007      0.003      0.240      0.810      -0.005       0.006\n","glucose                     0.0053      0.002      3.146      0.002       0.002       0.009\n","===========================================================================================\n","Saturated model -- p-value:  0.0\n","Pearson2 / Df 0.9967685069047872\n","Confusion matrix:  [[642 274]\n"," [305 639]]\n","Accuracy:  0.689\n","Sensitivity:  0.677\n","Specificity:  0.701\n","              precision    recall  f1-score   support\n","\n","           0      0.678     0.701     0.689       916\n","           1      0.700     0.677     0.688       944\n","\n","    accuracy                          0.689      1860\n","   macro avg      0.689     0.689     0.689      1860\n","weighted avg      0.689     0.689     0.689      1860\n","\n"]}],"source":["X = df_upsampled.iloc[:, :-1];\n","y = df_upsampled['TenYearCHD'];\n","\n","# Here we define training and testing sets.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0,shuffle=True);\n","\n","aux = pd.concat([X_train, y_train], axis = 1);\n","\n","model  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + age + education + C(currentSmoker) + \\\n","                             cigsPerDay + C(BPMeds) + C(prevalentStroke) + C(prevalentHyp) + C(diabetes) + \\\n","                             totChol + sysBP + diaBP + BMI + heartRate+ glucose\", family = sm.families.Binomial(),\n","                             data=aux);\n","result = model.fit();\n","print(result.summary());\n","\n","### Checking Overdispersion ###\n","\n","# Since there are many continuous predictors, it is highly likely that the responses are ungrouped,\n","# in which case the overdispersion cannot occur.\n","# But we will check it anyway.\n","\n","dev = result.deviance; # Residual Deviance\n","dof = result.df_resid; # Degree of freedoms of Residuals\n","pvalue = 1 - scipy.stats.chi2.cdf(dev, dof); # p-value\n","\n","# H0: Logistic regression model provides an adequate fit for the data\n","# H1: Logistic regression model does not provide an adequate fit for the data\n","\n","if pvalue < 0.05:\n","    print(\"Saturated model -- p-value: \", pvalue);\n","else :\n","    print(\"Logistic model is ok -- p-value=\", pvalue);\n","\n","# Rules of thumb\n","\n","# Calculation of Pearson chi2 / n - (p+1)\n","print(\"Pearson2 / Df\", result.pearson_chi2 / result.df_resid);\n","# This value is close to 1.  So the model provides an adequate fit for the data\n","\n","### Predictions ###\n","predictions = result.predict(X_test);\n","predictions_nominal = [ 0 if x < 0.5 else 1 for x in predictions];\n","\n","from sklearn.metrics import confusion_matrix, classification_report\n","cm = confusion_matrix(y_test, predictions_nominal)\n","print(\"Confusion matrix: \", cm);\n","# The diagonal elements of the confusion matrix indicate correct predictions,\n","#  while the off-diagonals represent incorrect predictions\n","\n","# The logistic regression correctly predicted the 10 year risk of coronary heart disease 68.87% of the times\n","print(\"Accuracy: \", round(np.sum(np.diagonal(cm))/np.sum(cm),3));\n","\n","# The model correctly predicted 67.7% of the times those with a 10 year risk of coronary heart disease\n","print(\"Sensitivity: \", round(cm[1,1]/np.sum(cm[1,:]),3));\n","\n","# The model correctly predicted 70.7% of the times those without a 10 year risk of coronary heart disease\n","print(\"Specificity: \", round(cm[0,0]/np.sum(cm[0,:]),3));\n","\n","# We can also get those values as follows\n","print(classification_report(y_test,\n","                            predictions_nominal,\n","                            digits = 3))\n","\n"]},{"cell_type":"markdown","id":"2c40ebcb","metadata":{"id":"2c40ebcb"},"source":["## Question 3"]},{"cell_type":"code","execution_count":null,"id":"85a23c54","metadata":{"id":"85a23c54","outputId":"8e42f2b6-e85f-4923-87e2-34ea1ed61765"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cumulative variability explained by PCs: \n"," [0.26 0.37 0.48 0.58 0.68 0.77 0.85 0.92 0.98 1.  ]\n","                 Generalized Linear Model Regression Results                  \n","==============================================================================\n","Dep. Variable:             TenYearCHD   No. Observations:                 4338\n","Model:                            GLM   Df Residuals:                     4326\n","Model Family:                Binomial   Df Model:                           11\n","Link Function:                  Logit   Scale:                          1.0000\n","Method:                          IRLS   Log-Likelihood:                -2626.0\n","Date:                Fri, 22 Mar 2024   Deviance:                       5252.1\n","Time:                        11:10:03   Pearson chi2:                 4.31e+03\n","No. Iterations:                     4   Pseudo R-squ. (CS):             0.1610\n","Covariance Type:            nonrobust                                         \n","========================================================================================\n","                           coef    std err          z      P>|z|      [0.025      0.975]\n","----------------------------------------------------------------------------------------\n","Intercept               -0.3785      0.063     -6.043      0.000      -0.501      -0.256\n","C(male)[T.1]             0.4686      0.073      6.424      0.000       0.326       0.612\n","C(prevalentHyp)[T.1]     0.3522      0.096      3.655      0.000       0.163       0.541\n","PC1                      0.3730      0.032     11.721      0.000       0.311       0.435\n","PC2                     -0.0697      0.031     -2.223      0.026      -0.131      -0.008\n","PC4                      0.3026      0.037      8.213      0.000       0.230       0.375\n","PC5                      0.0784      0.036      2.150      0.032       0.007       0.150\n","PC6                     -0.2705      0.038     -7.173      0.000      -0.344      -0.197\n","PC7                     -0.1748      0.040     -4.424      0.000      -0.252      -0.097\n","PC8                     -0.2695      0.040     -6.746      0.000      -0.348      -0.191\n","PC9                     -0.3267      0.044     -7.392      0.000      -0.413      -0.240\n","PC10                     0.2022      0.082      2.461      0.014       0.041       0.363\n","========================================================================================\n","Confusion matrix:  [[642 274]\n"," [310 634]]\n","Acuraccy:  0.686\n","Sensitivity:  0.677\n","Specificity:  0.701\n","              precision    recall  f1-score   support\n","\n","           0      0.674     0.701     0.687       916\n","           1      0.698     0.672     0.685       944\n","\n","    accuracy                          0.686      1860\n","   macro avg      0.686     0.686     0.686      1860\n","weighted avg      0.686     0.686     0.686      1860\n","\n"]}],"source":["# If multicollinearity is a problem, we can always transform the variables via PCA\n","# and then fit the logistic regression model.\n","\n","Xc_train  = X_train.drop([\"male\",\"currentSmoker\",\"prevalentStroke\",\"prevalentHyp\",\"diabetes\"], axis = 1); # continuous variables\n","\n","scaler       = StandardScaler();     # Creating object\n","fitted       = scaler.fit(Xc_train); # Calculating means and SDs\n","Xc_train_std = fitted.transform(Xc_train); # Standardising data\n","\n","pca        = PCA(n_components=Xc_train_std.shape[1]); # Specifying number of PCs\n","pca_fitted = pca.fit(Xc_train_std);                   # Calculating PC transformation\n","PCAs       = pca_fitted.transform(Xc_train_std);      # Generating PCs\n","print(\"Cumulative variability explained by PCs: \\n\", np.round(np.cumsum(pca.explained_variance_ratio_), 2))\n","\n","PCs = pd.DataFrame(data = PCAs,\n","                   columns = [\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\", \"PC7\", \"PC8\", \"PC9\", \"PC10\"])\n","\n","X_train.reset_index(drop=True, inplace=True) # removing row names\n","y_train.reset_index(drop=True, inplace=True) # removing row names\n","\n","DF = pd.concat([y_train, X_train[[\"male\",\"currentSmoker\",\"prevalentStroke\",\"prevalentHyp\",\"diabetes\"]], PCs], axis = 1);\n","\n","# We fit a linear model with all the principal components and perform back selection\n","\n","# Model with all the principal components\n","#model_pca  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + C(currentSmoker) + C(prevalentStroke) + C(prevalentHyp) + C(diabetes) +\\\n","#                             PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10\", family = sm.families.Binomial(),\n","#                             data=DF);\n","\n","# Removing diabetes\n","#model_pca  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + C(currentSmoker) + C(prevalentStroke) + C(prevalentHyp) +\\\n","#                             PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10\", family = sm.families.Binomial(),\n","#                             data=DF);\n","\n","# Removing currentSmoker\n","#model_pca  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + C(prevalentStroke) + C(prevalentHyp) +\\\n","#                             PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10\", family = sm.families.Binomial(),\n","#                             data=DF);\n","\n","# Removing PC3\n","#model_pca  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + C(prevalentStroke) + C(prevalentHyp) +\\\n","#                             PC1 + PC2 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10\", family = sm.families.Binomial(),\n","#                             data=DF);\n","\n","# Removing stroke\n","model_pca  = sm.GLM.from_formula(\"TenYearCHD ~ C(male) + C(prevalentHyp) +\\\n","                             PC1 + PC2 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10\", family = sm.families.Binomial(),\n","                             data=DF);\n","\n","result_pca = model_pca.fit();\n","print(result_pca.summary());\n","\n","Xc_test = X_test.drop([\"male\",\"currentSmoker\",\"prevalentStroke\",\"prevalentHyp\",\"diabetes\"], axis = 1); # continuous variables\n","Xc_test_std = fitted.transform(Xc_test); # standardised data\n","\n","X_pca_test = pca_fitted.transform(Xc_test_std);\n","X_pca_test = pd.DataFrame(data = X_pca_test,\n","                   columns = [\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\", \"PC7\", \"PC8\", \"PC9\", \"PC10\"])\n","\n","X_test.reset_index(drop=True, inplace=True) # removing row names\n","y_test.reset_index(drop=True, inplace=True) # removing row names\n","X_pca_test = pd.concat([y_test, X_test[[\"male\",\"currentSmoker\",\"prevalentStroke\",\"prevalentHyp\",\"diabetes\"]], X_pca_test], axis = 1);\n","\n","predictions_pca = result_pca.predict(X_pca_test);\n","predictions_pca_nominal = [ 0 if x < 0.5 else 1 for x in predictions_pca];\n","\n","from sklearn.metrics import confusion_matrix, classification_report\n","cm_pca = confusion_matrix(y_test, predictions_pca_nominal)\n","print(\"Confusion matrix: \", cm_pca);\n","# The diagonal elements of the confusion matrix indicate correct predictions,\n","#  while the off-diagonals represent incorrect predictions\n","\n","# The logistic regression correctly predicted the 10 year risk of coronary heart disease 68.87% of the times\n","print(\"Acuraccy: \", round(np.sum(np.diagonal(cm_pca))/np.sum(cm_pca),3));\n","\n","# The model correctly predicted 67.7% of the times those with a 10 year risk of coronary heart disease\n","print(\"Sensitivity: \", round(cm[1,1]/np.sum(cm_pca[1,:]),3));\n","\n","# The model correctly predicted 70.7% of the times those without a 10 year risk of coronary heart disease\n","print(\"Specificity: \", round(cm[0,0]/np.sum(cm_pca[0,:]),3));\n","\n","# We can also get those values as follows\n","print(classification_report(y_test,\n","                            predictions_pca_nominal,\n","                            digits = 3))\n","\n","# The results are similar to the ones obtain when using the original predictors.\n","# However, the PC predictors are not correlated.\n"]},{"cell_type":"code","execution_count":null,"id":"29c1a5c5","metadata":{"id":"29c1a5c5"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}