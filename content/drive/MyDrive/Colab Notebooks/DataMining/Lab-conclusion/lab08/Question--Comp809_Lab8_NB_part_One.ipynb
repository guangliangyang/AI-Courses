{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eaa161b",
   "metadata": {},
   "source": [
    "### Importing the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9271747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.metrics import precision_score, recall_score, auc\n",
    "from sklearn.metrics import roc_curve, accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import shapiro, normaltest\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7302d50e",
   "metadata": {},
   "source": [
    "## Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d961eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 Load library and dataset\n",
    "\n",
    "from sklearn.**** import *****\n",
    "\n",
    "myiris = pd.*****('Iris.xlsx') \n",
    "\n",
    "print(\"data summary\")\n",
    "print(myiris.describe())\n",
    "\n",
    "#Identify predictors and target\n",
    "predictors = myiris.drop(\"****\",axis=1)\n",
    "target = myiris['*****']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de6e14d",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2bbb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 Visualize the distribution of the input variables within the subset of your dataset\n",
    "\n",
    "# Prepare the plot grid\n",
    "fig, axs = plt.subplots(4, 2, figsize=(12, 16))  # 4 rows for histograms and Q-Q plots of 4 features\n",
    "\n",
    "# Loop over each feature to create a histogram and a Q-Q plot\n",
    "for index, feature in enumerate(['*****', '****', '****', '****']):\n",
    "    # Histogram\n",
    "    axs[index, 0].hist(myiris[*****], bins=20, color='skyblue', edgecolor='black')\n",
    "    axs[index, 0].set_title(f'Histogram of {feature}')\n",
    "    axs[index, 0].set_xlabel(f'{feature}')\n",
    "    axs[index, 0].set_ylabel('Frequency')\n",
    "\n",
    "    # Q-Q plot\n",
    "    stats.probplot(*****[feature], dist=\"norm\", plot=axs[index, 1])\n",
    "    axs[index, 1].set_title(f'Q-Q Plot of {feature}')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.*****()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49dc00d",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.1: By using k-fold cross-validation, split your dataset into training and testing (33%) subset.\n",
    "\n",
    "# Setup for 5-fold cross-validation\n",
    "kf = ****(n_splits=****, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff51a4d",
   "metadata": {},
   "source": [
    "### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ae0917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Task 4: Fit a Gaussian Naive Bayes model\n",
    "\n",
    "# Initialize Gaussian Naive Bayes\n",
    "gnb = *****()\n",
    "\n",
    "# To store the accuracies from each fold\n",
    "accuracies = []\n",
    "\n",
    "# Execute the k-fold cross-validation\n",
    "for train_index, test_index in kf.split(predictors):\n",
    "    # Correctly index the rows for training and testing data using .iloc for DataFrames\n",
    "    pred_train, ***** = ****.iloc[train_index], ****.iloc[test_index]\n",
    "    tar_train, **** = ****.iloc[train_index], ****.iloc[test_index]\n",
    "\n",
    "    # Training the model\n",
    "    gnb.fit(****, ****)\n",
    "\n",
    "    # Predicting the labels\n",
    "    tar_pred = gnb.predict(****)\n",
    "\n",
    "    # Calculating accuracy\n",
    "    accuracy = accuracy_score(****, ****)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Calculating the average accuracy across all folds\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy: {average_accuracy:.2%}')\n",
    "\n",
    "# Optionally, print accuracy for each fold\n",
    "for fold, acc in enumerate(accuracies, 1):\n",
    "    print(f'Fold {fold}: Accuracy = {acc:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057787af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3.2: Try to change your proportion to 20% for test sets. Explain your findings.\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(****) + 1), ****, marker='o', linestyle='-', color='b')\n",
    "plt.title('Accuracy per Fold')\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(range(1, len(accuracies) + 1))  # Ensure ticks correspond to fold numbers\n",
    "plt.grid(True)\n",
    "\n",
    "# Highlight the average accuracy\n",
    "plt.axhline(y=****, color='r', linestyle='--', label=f'Average Accuracy: {average_accuracy:.2%}')\n",
    "plt.legend()\n",
    "\n",
    "plt.****()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599e2df0",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d5358",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_pred = gnb.predict(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5.1. Generate the confusion matrix for your model and provide matrix\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = ****(****, ****)\n",
    "\n",
    "# Optionally, you can visualize the confusion matrix with seaborn\n",
    "ax = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3577600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5.2: Using the classification report, provide the performance metrics of the model.\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = ****(****, ****)\n",
    "report = classification_report(****, ****)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
